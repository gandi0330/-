import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

data_read = pd.read_csv('C:/Users/현명/Desktop/1234.csv',names=['station','bycicle','rental','population'])

#-------------------------------------------------------------
#초기 모델을 만들기 위해 train, test로 구분
data_train, data_test = train_test_split(data_read,test_size = 0.3, random_state =1)


x = data_train[['station','bycicle','population']]
y = data_train[['rental']]

x_t = data_test[['station','bycicle','population']]
y_t = data_test[['rental']]

#초기 lr_first 모델 train
lr_first = LinearRegression()
lr_first.fit(x,y)

#초기 모델의 mae 평가
mae = mean_absolute_error(y_t,lr_first.predict(x_t))

print("first lr's mae : ",mae)
#--------------------------------------------------------------

#k-fold 기법 사용 k = 8
#9개의 모델을 생성하여 기존의 mae보다 작은 모델을 lr_end로 반환

kf = KFold(n_splits=10, shuffle=True)
lr_end = LinearRegression()
lr_end = lr_first

for train_index, test_index in kf.split(data_train):
    lr = LinearRegression()

    train_ = data_train.iloc[train_index]
    val_ = data_train.iloc[test_index]

    train_x = train_[['station','bycicle','population']]
    train_y = train_[['rental']]

    val_x = val_[['station','bycicle','population']]
    val_y = val_[['rental']]

    lr.fit(train_x,train_y)

    if mae > mean_absolute_error(val_y,lr.predict(val_x)):
        print("new lr's mae = %d" %mean_absolute_error(val_y,lr.predict(val_x)))
        mae = mean_absolute_error(val_y,lr.predict(val_x))
        lr_end = lr

print("end lr's mae = %d" %mean_absolute_error(y_t,lr_end.predict(x_t)))
